{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNvuF2iuJkHNlToaQ93MRg2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanieleFG/Ciencias_de_Dados/blob/master/spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH02_a7A50iE",
        "outputId": "e8f8d056-0af8-41f6-ace9-d1a3b9a853de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de vendas por produto\n",
            "Produto id 101: Quantidade Total = 5, ValorTotal = 500.0\n",
            "Produto id 102: Quantidade Total = 19, ValorTotal = 1200.0\n",
            "Produto id 103: Quantidade Total = 20, ValorTotal = 978.0\n",
            "Produto id 104: Quantidade Total = 6, ValorTotal = 365.0\n",
            "Produto id 105: Quantidade Total = 10, ValorTotal = 109.0\n",
            "Produto id 106: Quantidade Total = 25, ValorTotal = 864.0\n",
            "Produto mais vendido: Produto ID 106 com 25\n",
            "Média de vendas por produto\n",
            "Produto id 101: Média = 100.00\n",
            "Produto id 102: Média = 63.16\n",
            "Produto id 103: Média = 48.90\n",
            "Produto id 104: Média = 60.83\n",
            "Produto id 105: Média = 10.90\n",
            "Produto id 106: Média = 34.56\n"
          ]
        }
      ],
      "source": [
        "# @title Texto de título padrão\n",
        "from pyspark import SparkContext\n",
        "import os\n",
        "sc = SparkContext(\"local\", \"Analise de Vendas\")\n",
        "\n",
        "file_path = \"vendas.csv\"\n",
        "# if not os.path.exists(file_path):\n",
        "#     print(f\"Erro: O arquivo '{file_path}' não foi encontrado.\")\n",
        "#     sc.stop()\n",
        "#     exit()\n",
        "\n",
        "\n",
        "vendas_rdd = sc.textFile(file_path)\n",
        "\n",
        "vendas_tuplas_rdd = vendas_rdd.map(lambda linha: tuple(linha.split(\",\")))\n",
        "\n",
        "produtos_rdd = vendas_tuplas_rdd.map(lambda venda: (venda[1], (int(venda[2]), float(venda[3]))))\n",
        "\n",
        "total_vendas_por_produto = produtos_rdd.reduceByKey(lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
        "print(\"Total de vendas por produto\")\n",
        "\n",
        "for produto in total_vendas_por_produto.collect():\n",
        "    print(f\"Produto id {produto[0]}: Quantidade Total = {produto[1][0]}, ValorTotal = {produto[1][1]}\")\n",
        "\n",
        "produto_mais_vendido = total_vendas_por_produto.reduce(lambda a,b: a if a[1][0] >b[1][0] else b)\n",
        "\n",
        "print(f\"Produto mais vendido: Produto ID {produto_mais_vendido[0]} com {produto_mais_vendido[1][0]}\")\n",
        "\n",
        "media_vendas_por_produto = total_vendas_por_produto.mapValues(lambda valor: valor[1] / valor[0])\n",
        "\n",
        "print(\"Média de vendas por produto\")\n",
        "\n",
        "for produto in media_vendas_por_produto.collect():\n",
        "    print(f\"Produto id {produto[0]}: Média = {produto[1]:.2f}\")\n",
        "\n",
        "sc.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "y6-vZlb7MqIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Analise de Vendas SQL\").getOrCreate()\n",
        "vendas_data = [\n",
        "    {\"data\": \"2025-01-01\", \"produto\": \"Produto A\", \"quantidade\": 100, \"preco_unitario\": 10.5},\n",
        "    {\"data\": \"2025-01-02\", \"produto\": \"Produto B\", \"quantidade\": 50, \"preco_unitario\": 8.2},\n",
        "    {\"data\": \"2025-01-03\", \"produto\": \"Produto A\", \"quantidade\": 75, \"preco_unitario\": 11.0},\n",
        "    {\"data\": \"2025-01-04\", \"produto\": \"Produto C\", \"quantidade\": 120, \"preco_unitario\": 9.8},\n",
        "    {\"data\": \"2025-01-05\", \"produto\": \"Produto B\", \"quantidade\": 60, \"preco_unitario\": 7.5}\n",
        "]\n",
        "\n",
        "vendas_df = spark.createDataFrame(vendas_data)\n",
        "\n",
        "produtos_data = [\n",
        "    {\"produto\": \"Produto A\", \"categoria\": \"Eletrônico\"},\n",
        "    {\"produto\": \"Produto B\", \"categoria\": \"Roupa\"},\n",
        "    {\"produto\": \"Produto C\", \"categoria\": \"Alimentos\"}\n",
        "]\n",
        "\n",
        "produtos_df = spark.createDataFrame(produtos_data)\n",
        "\n",
        "vendas_df.createOrReplaceTempView(\"vendas\")\n",
        "produtos_df.createOrReplaceTempView(\"produtos\")\n",
        "\n",
        "resultado = spark.sql(\"\"\"\n",
        "  SELECT\n",
        "    v.data,\n",
        "    v.produto,\n",
        "    v.quantidade,\n",
        "    v.preco_unitario,\n",
        "    p.categoria\n",
        "  FROM\n",
        "    vendas v\n",
        "  JOIN\n",
        "    produtos p ON v.produto = p.produto\n",
        "    ORDER BY v.data\n",
        "\"\"\")\n",
        "\n",
        "print(\"Resultado da consulta sql\")\n",
        "\n",
        "resultado.show()\n",
        "\n",
        "total_por_categoria = spark.sql(\"\"\"\n",
        "      SELECT\n",
        "        p.categoria,\n",
        "        SUM(v.quantidade * v.preco_unitario) AS total_vendas\n",
        "      FROM\n",
        "        vendas v\n",
        "      JOIN\n",
        "        produtos p ON v.produto = p.produto\n",
        "      GROUP BY\n",
        "        p.categoria\n",
        "      ORDER BY\n",
        "        total_vendas DESC\n",
        "\"\"\")\n",
        "print(\"Total por categoria\")\n",
        "\n",
        "total_por_categoria.show()\n",
        "\n",
        "media_quantidade = vendas_df.select(avg(\"quantidade\").alias(\"media_quantidade\"))\n",
        "\n",
        "print(\"Média de quantidade\")\n",
        "\n",
        "media_quantidade.show()\n",
        "\n",
        "vendas_altas = vendas_df.filter(col(\"quantidade\") > 100)\n",
        "print(\"Vendas acima de 100\")\n",
        "\n",
        "vendas_altas.show()\n",
        "\n",
        "\n",
        "\n",
        "spark.stop()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMWL9NGKMyTX",
        "outputId": "b91c7c18-7ef3-4bea-8b4e-dd15fdfb6945"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da consulta sql\n",
            "+----------+---------+----------+--------------+----------+\n",
            "|      data|  produto|quantidade|preco_unitario| categoria|\n",
            "+----------+---------+----------+--------------+----------+\n",
            "|2025-01-01|Produto A|       100|          10.5|Eletrônico|\n",
            "|2025-01-02|Produto B|        50|           8.2|     Roupa|\n",
            "|2025-01-03|Produto A|        75|          11.0|Eletrônico|\n",
            "|2025-01-04|Produto C|       120|           9.8| Alimentos|\n",
            "|2025-01-05|Produto B|        60|           7.5|     Roupa|\n",
            "+----------+---------+----------+--------------+----------+\n",
            "\n",
            "Total por categoria\n",
            "+----------+------------+\n",
            "| categoria|total_vendas|\n",
            "+----------+------------+\n",
            "|Eletrônico|      1875.0|\n",
            "| Alimentos|      1176.0|\n",
            "|     Roupa|       860.0|\n",
            "+----------+------------+\n",
            "\n",
            "Média de quantidade\n",
            "+----------------+\n",
            "|media_quantidade|\n",
            "+----------------+\n",
            "|            81.0|\n",
            "+----------------+\n",
            "\n",
            "Vendas acima de 100\n",
            "+----------+--------------+---------+----------+\n",
            "|      data|preco_unitario|  produto|quantidade|\n",
            "+----------+--------------+---------+----------+\n",
            "|2025-01-04|           9.8|Produto C|       120|\n",
            "+----------+--------------+---------+----------+\n",
            "\n",
            "Vendas acima de 100\n",
            "+----------+--------------+---------+----------+\n",
            "|      data|preco_unitario|  produto|quantidade|\n",
            "+----------+--------------+---------+----------+\n",
            "|2025-01-04|           9.8|Produto C|       120|\n",
            "+----------+--------------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "9EsqjcRDUVJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Processamento de dados empresa\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"vendas.csv\", header=True, inferSchema=True)\n",
        "clientes_df = spark.read.format(\"json\").load(\"clientes.json\")\n",
        "\n",
        "df.createOrReplaceTempView(\"vendas\")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "CqL0mkB9UXIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "wZpKO1CddJyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum , avg\n",
        "vendas_agregadas = vendas_df.groupBy(\"produto_id\").agg(\n",
        "    sum(\"quantidade\").alias(\"total_vendido\"),\n",
        "    sum(\"valor_unitario\").alias(\"valor_total\"),\n",
        "    avg(\"valor_unitario\").alias(\"preco_medio\"))\n",
        "vendas_agregadas.show()"
      ],
      "metadata": {
        "id": "ncd2EoEddKyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "RF8WDaSjeKaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import window\n",
        "\n",
        "vendas_stream_df = spark.readStream.format(\"kafka\").option(\"header\", \"true\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "  .option(\"subscribe\", \"vendas\") \\\n",
        "  .load()\n",
        "\n",
        "vendas_stream_df = vendas_stream_df.selectExpr(\"CAST(value AS STRING)\").alias(\"value\")\n",
        "vendas_stream_df = vendas_stream_df.selectExpr(\"split(value, ',')[0] as produto_id\",\n",
        "                                               \"split(value, ',')[1] as quantidade\",\n",
        "                                               \"split(value, ',')[2] as valor\")\n",
        "\n",
        "vendas_agregadas_stream = vendas_stream_df.groupBy(\n",
        "    window(\"timestamp\", \"1 minute\"),\n",
        "    \"produto_id\"\n",
        ").agg(\n",
        "    sum(\"quantidade\").alias(\"total_vendido\"),\n",
        "    sum(\"valor\").alias(\"valor_total\")\n",
        ")\n",
        "\n",
        "query = vendas_agregadas_stream.writeStream \\\n",
        "  .outputMode(\"complete\") \\\n",
        "  .start()\n",
        "\n",
        "query.awaitTermination()"
      ],
      "metadata": {
        "id": "3_idT2wseLEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}